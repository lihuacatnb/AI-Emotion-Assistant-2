# åŸºäºOllamaçš„AIæƒ…ç»ªåŠ©æ‰‹

---

ğŸ“– **æœ¬ README ä¸ºä¸­æ–‡ç‰ˆæœ¬**ï¼Œç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹ [English version](./README_EN.md)  

---

## 1.é¡¹ç›®ç®€ä»‹
æœ¬é¡¹ç›®æ„å»ºäº†ä¸€ä¸ªåŸºäº Ollama å¹³å° çš„æœ¬åœ° AI æƒ…ç»ªåŠ©æ‰‹ç³»ç»Ÿï¼Œæ”¯æŒæƒ…æ„Ÿåˆ†æç­‰åŠŸèƒ½ï¼Œé€‚ç”¨äºæœ¬ç§‘æ¯•ä¸šè®¾è®¡ã€‚

## 2.é¡¹ç›®åŸºç¡€
- å‰ç«¯ä½¿ç”¨ Vue æ¡†æ¶ï¼ŒåŸºäºå¼€æºé¡¹ç›®[Fully-featured & beautiful web interface for Ollama LLMs](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)
- åç«¯çš„æ¨¡å‹ä½¿ç”¨ [L3-Umbral-Mind-RP-v0.3-8B-Q8_0-GGUF](https://huggingface.co/Ransss/L3-Umbral-Mind-RP-v0.3-8B-Q8_0-GGUF)

## 3.é¡¹ç›®è¿è¡Œ
### ï¼ˆ1ï¼‰å‰ç«¯ç¯å¢ƒ
Node 18.16.0
### ï¼ˆ2ï¼‰å‰ç«¯è¿è¡Œ
- npm install
- npm run dev
### ï¼ˆ3ï¼‰åç«¯ç¯å¢ƒ
Ollama<br>
### ï¼ˆ4ï¼‰åç«¯è¿è¡Œ ï¼ˆBack-end Runningï¼‰
ä¸‹è½½æ¨¡å‹æ–‡ä»¶åï¼Œåœ¨æ¨¡å‹æ–‡ä»¶å¤¹ä¸‹æ–°å»ºä¸€ä¸ª __Modelfile__  æ–‡ä»¶ï¼Œç›®å½•ç»“æ„ç¤ºä¾‹ï¼š<br>
<img src="/show11.png"/><br>
ä½¿ç”¨è®°äº‹æœ¬æˆ–ä»»æ„æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ `Modelfile` æ–‡ä»¶ï¼Œè¾“å…¥ä»¥ä¸‹å†…å®¹ï¼š<br>

```plaintext
    FROM <æ¨¡å‹è·¯å¾„>/l3-umbral-mind-rp-v0.3-8b-q8_0.gguf
```
<br>
Modelfileæ–‡ä»¶ç¤ºä¾‹ï¼š

```plaintext
    FROM C:/Users/lihuacat/l3-umbral-mind-rp-v0.3-8b-q8_0/l3-umbral-mind-rp-v0.3-8b-q8_0.gguf
```

<br>

åœ¨ cmd ä¸­è¿›å…¥ __æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„__ ï¼Œæ‰§è¡Œï¼š

```plaintext
    ollama create l3-umbral-mind-rp-v0.3-8b-q8_0 -f Modelfile
```
<br>
æµ‹è¯•è¿è¡Œï¼š

```plaintext
    ollama run l3-umbral-mind-rp-v0.3-8b-q8_0
```


## 4.å¼€å‘äººå‘˜
-ç‹¸çŒ«Cå‹AI
-æ„Ÿè°¢ç‡•äº¬ç†å·¥å­¦é™¢ __é™ˆç‚œå¯¼å¸ˆ__

## 5.é¡¹ç›®å±•ç¤º
<img src="/show-1.png"/><br>
<br>
<br>
<img src="/show2.png"/><br>
<br>

---

<p align="center">â­ï¸ å¦‚æœä½ è§‰å¾—æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ç‚¹ä¸ª Star æ”¯æŒä¸€ä¸‹ï¼ â­ï¸</p>
